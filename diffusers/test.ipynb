{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from torch import autocast\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MODEL_ID = \"CompVis/stable-diffusion-v1-4\"\n",
    "DEVICE = \"cuda\"\n",
    "YOUR_TOKEN = \"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\"\n",
    " \n",
    "pipe = StableDiffusionPipeline.from_pretrained(MODEL_ID, revision=\"fp16\", torch_dtype=torch.float16, use_auth_token=YOUR_TOKEN)\n",
    "pipe.to(DEVICE)\n",
    " \n",
    "prompt = \"a dog painted by Katsuhika Hokusai\"\n",
    " \n",
    "with autocast(DEVICE):\n",
    "  image = pipe(prompt, guidance_scale=7.5)[\"sample\"][0]\n",
    "  image.save(\"test.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: POSITIVE, with score: 0.9998\n",
      "label: NEGATIVE, with score: 0.5309\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline \n",
    "classifier = pipeline('sentiment-analysis') \n",
    "results = classifier([\"We are very happy to show you the ðŸ¤— Transformers library.\", \n",
    "           \"We hope you don't hate it.\"]) \n",
    "for result in results: \n",
    "    print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\nLDMTextToImagePipeline requires the transformers library but it was not found in your environment. You can install it with pip: `pip\ninstall transformers`\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mã‚»ãƒ«4 ã‚’ /Users/tkawabat/git/notebook/diffusers/test.ipynb\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tkawabat/git/notebook/diffusers/test.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model_id \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCompVis/ldm-text2im-large-256\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tkawabat/git/notebook/diffusers/test.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# load model and scheduler\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/tkawabat/git/notebook/diffusers/test.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m ldm \u001b[39m=\u001b[39m DiffusionPipeline\u001b[39m.\u001b[39;49mfrom_pretrained(model_id)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tkawabat/git/notebook/diffusers/test.ipynb#W3sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# run pipeline in inference (sample random noise and denoise)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tkawabat/git/notebook/diffusers/test.ipynb#W3sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m prompt \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mA painting of a squirrel eating a burger\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/diffusers/lib/python3.10/site-packages/diffusers/pipeline_utils.py:182\u001b[0m, in \u001b[0;36mDiffusionPipeline.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m expected_modules \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(inspect\u001b[39m.\u001b[39msignature(pipeline_class\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m)\u001b[39m.\u001b[39mparameters\u001b[39m.\u001b[39mkeys())\n\u001b[1;32m    180\u001b[0m passed_class_obj \u001b[39m=\u001b[39m {k: kwargs\u001b[39m.\u001b[39mpop(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m expected_modules \u001b[39mif\u001b[39;00m k \u001b[39min\u001b[39;00m kwargs}\n\u001b[0;32m--> 182\u001b[0m init_dict, _ \u001b[39m=\u001b[39m pipeline_class\u001b[39m.\u001b[39;49mextract_init_dict(config_dict, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    184\u001b[0m init_kwargs \u001b[39m=\u001b[39m {}\n\u001b[1;32m    186\u001b[0m \u001b[39m# import it here to avoid circular import\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/diffusers/lib/python3.10/site-packages/diffusers/utils/import_utils.py:255\u001b[0m, in \u001b[0;36mDummyObject.__getattr__\u001b[0;34m(cls, key)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[39mif\u001b[39;00m key\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    254\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__getattr__\u001b[39m(\u001b[39mcls\u001b[39m, key)\n\u001b[0;32m--> 255\u001b[0m requires_backends(\u001b[39mcls\u001b[39;49m, \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_backends)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/diffusers/lib/python3.10/site-packages/diffusers/utils/import_utils.py:243\u001b[0m, in \u001b[0;36mrequires_backends\u001b[0;34m(obj, backends)\u001b[0m\n\u001b[1;32m    241\u001b[0m failed \u001b[39m=\u001b[39m [msg\u001b[39m.\u001b[39mformat(name) \u001b[39mfor\u001b[39;00m available, msg \u001b[39min\u001b[39;00m checks \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m available()]\n\u001b[1;32m    242\u001b[0m \u001b[39mif\u001b[39;00m failed:\n\u001b[0;32m--> 243\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(failed))\n",
      "\u001b[0;31mImportError\u001b[0m: \nLDMTextToImagePipeline requires the transformers library but it was not found in your environment. You can install it with pip: `pip\ninstall transformers`\n"
     ]
    }
   ],
   "source": [
    "from diffusers import DiffusionPipeline\n",
    " \n",
    "model_id = \"CompVis/ldm-text2im-large-256\"\n",
    " \n",
    "# load model and scheduler\n",
    "ldm = DiffusionPipeline.from_pretrained(model_id)\n",
    " \n",
    "# run pipeline in inference (sample random noise and denoise)\n",
    "prompt = \"A painting of a squirrel eating a burger\"\n",
    "images = ldm([prompt], num_inference_steps=50, eta=0.3, guidance_scale=6)[\"sample\"]\n",
    " \n",
    "# save images\n",
    "for idx, image in enumerate(images):\n",
    "    image.save(f\"squirrel-{idx}.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit ('diffusers')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bd955534b2f33584f7dacd71f2bd9704a8c937d7372620ce81e3b9c6e1042ccb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
