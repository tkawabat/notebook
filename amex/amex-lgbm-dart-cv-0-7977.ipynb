{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5"},"source":["# Comments:\n","    \n","This is an improvement of my baseline, you can find it here: https://www.kaggle.com/code/ragnar123/amex-lgbm-dart-cv-0-7963\n","\n","The main difference between this solution and previous one is that we add new features and do seed blend to boost LB. Single 5 kfold model using seed 42 achieve an out of folds CV of 0.7977 and a public leaderboard of 0.799. If we use seed blend (train three different models using seed 42, 52, 62 and then average predictions) the LB boost niceley.\n","\n","The main features that boost CV are the following:\n","\n","* The difference between last value and the lag1\n","* The difference between last value and the average (this features gives a nice boost)\n","\n","This feature engineer is done on all the last columns, so we actually add a lot of features, this model used 1368 features.\n","\n","I uploaded test predictions to avoid running training and inference\n","\n","Next Steps:\n","\n","* Could try feature selection, maybe a lot of the feature are just noise, actually I perform permutation importance and I reduce the amount of features to 1000 app and the CV was almost the same. Maybe there is a better feature selection technique that can boost performance.\n","\n","* Could try different models, maybe some neural network with the same features or a subset of the features and then blend with LGBM can work, in my experience blending tree models and neural network works great because they are very diverse so the boost is nice\n","\n","* Could try more feature engineering, maybe we can create more features that extract the hidden signal of the dataset, actually I would first work on this option and really try to capture all the signal that the dataset has."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 欠損値あるときのagg\n","# カテゴリデータでどの値持っているか\n","# countは一つで良さそう"]},{"cell_type":"markdown","metadata":{},"source":["# Preprocessing"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-08-03T05:18:39.449382Z","iopub.status.busy":"2022-08-03T05:18:39.448797Z","iopub.status.idle":"2022-08-03T05:18:41.960326Z","shell.execute_reply":"2022-08-03T05:18:41.959070Z","shell.execute_reply.started":"2022-08-03T05:18:39.449257Z"},"trusted":true},"outputs":[],"source":["# ====================================================\n","# Library\n","# ====================================================\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","# import itertools\n","\n","import gc, os\n","import random\n","import scipy as sp\n","import numpy as np\n","import pandas as pd\n","import joblib\n","import itertools\n","pd.set_option('display.max_rows', 500)\n","pd.set_option('display.max_columns', 500)\n","pd.set_option('display.width', 1000)\n","from tqdm.auto import tqdm\n","from sklearn.model_selection import StratifiedKFold, train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","import lightgbm as lgb\n","from itertools import combinations"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-08-03T05:18:41.963068Z","iopub.status.busy":"2022-08-03T05:18:41.962678Z","iopub.status.idle":"2022-08-03T05:18:41.979285Z","shell.execute_reply":"2022-08-03T05:18:41.977922Z","shell.execute_reply.started":"2022-08-03T05:18:41.963008Z"},"trusted":true},"outputs":[],"source":["# ====================================================\n","# Configurations\n","# ====================================================\n","class CFG:\n","    input_dir = \"./work/\"\n","    # input_dir = \"./\"\n","    seed = 42\n","    n_folds = 5\n","    target = 'target'\n","    boosting_type = 'dart'\n","    metric = 'binary_logloss'\n","\n","# ====================================================\n","# Seed everything\n","# ====================================================\n","def seed_everything(seed):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","\n","# ====================================================\n","# Get the difference\n","# ====================================================\n","def get_difference(data, num_features):\n","    df1 = []\n","    customer_ids = []\n","    for customer_id, df in tqdm(data.groupby(['customer_ID'])):\n","        # Get the differences\n","        diff_df1 = df[num_features].diff(1).iloc[[-1]].values.astype(np.float32)\n","        # Append to lists\n","        df1.append(diff_df1)\n","        customer_ids.append(customer_id)\n","    # Concatenate\n","    df1 = np.concatenate(df1, axis = 0)\n","    # Transform to dataframe\n","    df1 = pd.DataFrame(df1, columns = [col + '_diff1' for col in df[num_features].columns])\n","    # Add customer id\n","    df1['customer_ID'] = customer_ids\n","    return df1\n","\n","def preprocess(data):\n","    features = data.drop(['customer_ID', 'S_2', 'B_29', 'target'], errors='ignore', axis = 1).columns.to_list()\n","    cat_features = [\n","            \"B_30\",\n","            \"B_38\",\n","            \"D_114\",\n","            \"D_116\",\n","            \"D_117\",\n","            \"D_120\",\n","            \"D_126\",\n","            \"D_63\",\n","            \"D_64\",\n","            \"D_66\",\n","            \"D_68\",\n","        ]\n","    num_features = [col for col in features if col not in cat_features]\n","\n","    print(\"start num agg\")\n","    num_agg = data.groupby(\"customer_ID\")[num_features].agg(['mean', 'std', 'min', 'max', 'last'])\n","    num_agg.columns = ['_'.join(x) for x in num_agg.columns]\n","    num_agg.reset_index(inplace = True)\n","    \n","    print(\"start cat agg\")\n","    cat_agg = data.groupby(\"customer_ID\")[cat_features].agg(['count', 'last', 'nunique'])\n","    cat_agg.columns = ['_'.join(x) for x in cat_agg.columns]\n","    cat_agg.reset_index(inplace = True)\n","    \n","    print(\"start get diff\")\n","    diff = get_difference(data, num_features)\n","    \n","    # merge\n","    print(\"start merge\")\n","    data = num_agg.merge(cat_agg, how = 'inner', on = 'customer_ID').merge(diff, how = 'inner', on = 'customer_ID')\n","    del num_agg, cat_agg, diff\n","    gc.collect()\n","    return data"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-08-03T03:54:26.476910Z","iopub.status.busy":"2022-08-03T03:54:26.475627Z","iopub.status.idle":"2022-08-03T04:19:22.898376Z","shell.execute_reply":"2022-08-03T04:19:22.897046Z","shell.execute_reply.started":"2022-08-03T03:54:26.476867Z"},"trusted":true},"outputs":[],"source":["%%time\n","df = pd.read_feather('../input/amexfeather/train_data.ftr')\n","df = preprocess(df)\n","train_labels = pd.read_csv(\"../input/amex-default-prediction/train_labels.csv\")\n","df = df.merge(train_labels, how = 'inner', on = 'customer_ID')\n","\n","df.info()\n","df.to_feather('./train_fe.feather')\n","\n","del df, train_labels\n","gc.collect()"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-08-03T04:19:22.901610Z","iopub.status.busy":"2022-08-03T04:19:22.901125Z","iopub.status.idle":"2022-08-03T04:45:07.545595Z","shell.execute_reply":"2022-08-03T04:45:07.544426Z","shell.execute_reply.started":"2022-08-03T04:19:22.901558Z"},"trusted":true},"outputs":[],"source":["%%time\n","df = pd.read_feather('../input/amexfeather/test_data.ftr')\n","df = df[df.customer_ID.str.contains('^[0-7]')]\n","gc.collect()\n","df = preprocess(df)\n","\n","df.info()\n","df.to_feather('./test_fe.feather')\n","\n","del df\n","gc.collect()"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-08-03T04:45:07.547985Z","iopub.status.busy":"2022-08-03T04:45:07.547513Z","iopub.status.idle":"2022-08-03T05:11:22.572051Z","shell.execute_reply":"2022-08-03T05:11:22.567834Z","shell.execute_reply.started":"2022-08-03T04:45:07.547940Z"},"trusted":true},"outputs":[],"source":["%time\n","df = pd.read_feather('../input/amexfeather/test_data.ftr')\n","df = df[~df.customer_ID.str.contains('^[0-7]')]\n","gc.collect()\n","df = preprocess(df)\n","\n","df.info()\n","df2 = pd.read_feather('./test_fe.feather')\n","df = pd.concat([df, df2])\n","df.reset_index()\n","df.to_feather('./test_fe.feather')\n","\n","del df, df2\n","gc.collect()"]},{"cell_type":"markdown","metadata":{},"source":["# Training & Inference"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-08-03T05:18:47.034641Z","iopub.status.busy":"2022-08-03T05:18:47.034212Z","iopub.status.idle":"2022-08-03T05:18:47.069202Z","shell.execute_reply":"2022-08-03T05:18:47.067857Z","shell.execute_reply.started":"2022-08-03T05:18:47.034606Z"},"trusted":true},"outputs":[],"source":["# ====================================================\n","# Read data\n","# ====================================================\n","def read_data():\n","    train = pd.read_feather(CFG.input_dir + 'train_fe.feather')\n","    test = pd.read_feather(CFG.input_dir + 'test_fe.feather')\n","    return train, test\n","\n","# ====================================================\n","# Amex metric\n","# ====================================================\n","def amex_metric(y_true, y_pred):\n","    labels = np.transpose(np.array([y_true, y_pred]))\n","    labels = labels[labels[:, 1].argsort()[::-1]]\n","    weights = np.where(labels[:,0]==0, 20, 1)\n","    cut_vals = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n","    top_four = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n","    gini = [0,0]\n","    for i in [1,0]:\n","        labels = np.transpose(np.array([y_true, y_pred]))\n","        labels = labels[labels[:, i].argsort()[::-1]]\n","        weight = np.where(labels[:,0]==0, 20, 1)\n","        weight_random = np.cumsum(weight / np.sum(weight))\n","        total_pos = np.sum(labels[:, 0] *  weight)\n","        cum_pos_found = np.cumsum(labels[:, 0] * weight)\n","        lorentz = cum_pos_found / total_pos\n","        gini[i] = np.sum((lorentz - weight_random) * weight)\n","    return 0.5 * (gini[1]/gini[0] + top_four)\n","\n","# ====================================================\n","# LGBM amex metric\n","# ====================================================\n","def lgb_amex_metric(y_pred, y_true):\n","    y_true = y_true.get_label()\n","    return 'amex_metric', amex_metric(y_true, y_pred), True\n","\n","# ====================================================\n","# Train & Evaluate\n","# ====================================================\n","def train_and_evaluate(train, test):\n","    # Label encode categorical features\n","    cat_features = [\n","        \"B_30\",\n","        \"B_38\",\n","        \"D_114\",\n","        \"D_116\",\n","        \"D_117\",\n","        \"D_120\",\n","        \"D_126\",\n","        \"D_63\",\n","        \"D_64\",\n","        \"D_66\",\n","        \"D_68\"\n","    ]\n","    cat_features = [f\"{cf}_last\" for cf in cat_features]\n","    for cat_col in cat_features:\n","        encoder = LabelEncoder()\n","        train[cat_col] = encoder.fit_transform(train[cat_col])\n","        test[cat_col] = encoder.transform(test[cat_col])\n","    \n","    # Round last float features to 2 decimal place\n","    num_cols = list(train.dtypes[(train.dtypes == 'float32') | (train.dtypes == 'float64')].index)\n","    num_cols = [col for col in num_cols if 'last' in col]\n","    for col in num_cols:\n","        train[col + '_round2'] = train[col].round(2)\n","        test[col + '_round2'] = test[col].round(2)\n","    # Get the difference between last and mean\n","    num_cols = [col for col in train.columns if 'last' in col]\n","    num_cols = [col[:-5] for col in num_cols if 'round' not in col]\n","    for col in num_cols:\n","        try:\n","            train[f'{col}_last_mean_diff'] = train[f'{col}_last'] - train[f'{col}_mean']\n","            test[f'{col}_last_mean_diff'] = test[f'{col}_last'] - test[f'{col}_mean']\n","        except:\n","            pass\n","    # Transform float64 and float32 to float16\n","    num_cols = list(train.dtypes[(train.dtypes == 'float32') | (train.dtypes == 'float64')].index)\n","    for col in tqdm(num_cols):\n","        train[col] = train[col].astype(np.float16)\n","        test[col] = test[col].astype(np.float16)\n","    # Get feature list\n","    features = [col for col in train.columns if col not in ['customer_ID', CFG.target]]\n","    params = {\n","        'objective': 'binary',\n","        'metric': CFG.metric,\n","        'boosting': CFG.boosting_type,\n","        'seed': CFG.seed,\n","        'num_leaves': 100,\n","        'learning_rate': 0.01,\n","        'feature_fraction': 0.20,\n","        'bagging_freq': 10,\n","        'bagging_fraction': 0.50,\n","        'n_jobs': -1,\n","        'lambda_l2': 2,\n","        'min_data_in_leaf': 40,\n","        }\n","    # Create a numpy array to store test predictions\n","    test_predictions = np.zeros(len(test))\n","    # Create a numpy array to store out of folds predictions\n","    oof_predictions = np.zeros(len(train))\n","    kfold = StratifiedKFold(n_splits = CFG.n_folds, shuffle = True, random_state = CFG.seed)\n","    for fold, (trn_ind, val_ind) in enumerate(kfold.split(train, train[CFG.target])):\n","        print(' ')\n","        print('-'*50)\n","        print(f'Training fold {fold} with {len(features)} features...')\n","        x_train, x_val = train[features].iloc[trn_ind], train[features].iloc[val_ind]\n","        y_train, y_val = train[CFG.target].iloc[trn_ind], train[CFG.target].iloc[val_ind]\n","        lgb_train = lgb.Dataset(x_train, y_train, categorical_feature = cat_features)\n","        lgb_valid = lgb.Dataset(x_val, y_val, categorical_feature = cat_features)\n","        model = lgb.train(\n","            params = params,\n","            train_set = lgb_train,\n","            num_boost_round = 10500,\n","            valid_sets = [lgb_train, lgb_valid],\n","            early_stopping_rounds = 1500,\n","            verbose_eval = 500,\n","            feval = lgb_amex_metric\n","            )\n","        # Save best model\n","        joblib.dump(model, f'./lgbm_{CFG.boosting_type}_fold{fold}_seed{CFG.seed}.pkl')\n","        # Predict validation\n","        val_pred = model.predict(x_val)\n","        # Add to out of folds array\n","        oof_predictions[val_ind] = val_pred\n","        # Predict the test set\n","        test_pred = model.predict(test[features])\n","        test_predictions += test_pred / CFG.n_folds\n","        # Compute fold metric\n","        score = amex_metric(y_val, val_pred)\n","        print(f'Our fold {fold} CV score is {score}')\n","        del x_train, x_val, y_train, y_val, lgb_train, lgb_valid\n","        gc.collect()\n","    # Compute out of folds metric\n","    score = amex_metric(train[CFG.target], oof_predictions)\n","    print(f'Our out of folds CV score is {score}')\n","    # Create a dataframe to store out of folds predictions\n","    oof_df = pd.DataFrame({'customer_ID': train['customer_ID'], 'target': train[CFG.target], 'prediction': oof_predictions})\n","    oof_df.to_csv(f'./oof_lgbm_{CFG.boosting_type}_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n","    # Create a dataframe to store test prediction\n","    test_df = pd.DataFrame({'customer_ID': test['customer_ID'], 'prediction': test_predictions})\n","    test_df.to_csv(f'./test_lgbm_{CFG.boosting_type}_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-08-03T05:18:50.179072Z","iopub.status.busy":"2022-08-03T05:18:50.178599Z","iopub.status.idle":"2022-08-03T05:19:07.125591Z","shell.execute_reply":"2022-08-03T05:19:07.124540Z","shell.execute_reply.started":"2022-08-03T05:18:50.179008Z"},"trusted":true},"outputs":[],"source":["seed_everything(CFG.seed)\n","train, test = read_data()\n","\n","#train = train.drop(['target_mean', 'target_std', 'target_min', 'target_max', 'target_last', 'target_diff1'], axis=1)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0 [     0      1      2 ... 458910 458911 458912] [    12     18     27 ... 458893 458896 458904]\n","1 [     0      1      2 ... 458908 458910 458911] [     4      7     15 ... 458907 458909 458912]\n","2 [     1      4      7 ... 458908 458909 458912] [     0      2      3 ... 458903 458910 458911]\n","3 [     0      1      2 ... 458910 458911 458912] [     8     14     17 ... 458897 458905 458908]\n","4 [     0      2      3 ... 458910 458911 458912] [     1     10     11 ... 458888 458892 458895]\n"]}],"source":["kfold = StratifiedKFold(n_splits = CFG.n_folds, shuffle = True, random_state = CFG.seed)\n","for fold, (trn_ind, val_ind) in enumerate(kfold.split(train, train[CFG.target])):\n","    print(fold, trn_ind, val_ind)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-03T05:19:34.417513Z","iopub.status.busy":"2022-08-03T05:19:34.416561Z"},"trusted":true},"outputs":[],"source":["train_and_evaluate(train, test)"]},{"cell_type":"markdown","metadata":{},"source":["# Read Submission File\n","This is the submission file corresponding to the output of the previous pipeline (using the average blend of 3 seeds)"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-07-30T07:53:27.460438Z","iopub.status.busy":"2022-07-30T07:53:27.459914Z","iopub.status.idle":"2022-07-30T07:53:35.123716Z","shell.execute_reply":"2022-07-30T07:53:35.122632Z","shell.execute_reply.started":"2022-07-30T07:53:27.460359Z"},"trusted":true},"outputs":[],"source":["sub = pd.read_csv('../input/amex-sub/test_lgbm_baseline_5fold_seed_blend.csv')\n","sub.to_csv('test_lgbm_baseline_5fold_seed_blend.csv', index = False)"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["   a  b    c\n","0  0  1  2.0\n","1  0  1  NaN\n","2  0  2  NaN\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead tr th {\n","        text-align: left;\n","    }\n","\n","    .dataframe thead tr:last-of-type th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th></th>\n","      <th colspan=\"6\" halign=\"left\">b</th>\n","      <th colspan=\"6\" halign=\"left\">c</th>\n","    </tr>\n","    <tr>\n","      <th></th>\n","      <th>mean</th>\n","      <th>std</th>\n","      <th>min</th>\n","      <th>max</th>\n","      <th>last</th>\n","      <th>count</th>\n","      <th>mean</th>\n","      <th>std</th>\n","      <th>min</th>\n","      <th>max</th>\n","      <th>last</th>\n","      <th>count</th>\n","    </tr>\n","    <tr>\n","      <th>a</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.333333</td>\n","      <td>0.57735</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>2.0</td>\n","      <td>NaN</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          b                                c                         \n","       mean      std min max last count mean std  min  max last count\n","a                                                                    \n","0  1.333333  0.57735   1   2    2     3  2.0 NaN  2.0  2.0  2.0     1"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["tmp = pd.DataFrame([[0,1,2],[0,1], [0,2]], columns=[\"a\", \"b\", \"c\"],)\n","tmp.reset_index()\n","print(tmp)\n","tmp.groupby('a').agg(['mean', 'std', 'min', 'max', 'last', 'count'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.6 64-bit ('amex')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"vscode":{"interpreter":{"hash":"59ed42f60c23565e134b24c7847f2d708e2b3bb3b666a349ae1d72ca611aaa1b"}}},"nbformat":4,"nbformat_minor":4}
